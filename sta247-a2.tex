\documentclass{article}
\usepackage{amssymb,graphicx}
\usepackage{hyperref}
\usepackage{pgfplots}
\usepackage[fleqn]{amsmath}

\pgfplotsset{compat=1.6}
\pgfplotsset{soldot/.style={only marks,mark=*}}
\pgfplotsset{holdot/.style={fill=white,only marks,mark=*}}

\title{STA247 Fall 2015, Assignment 2}
\author{Connor Peet \#1001088208}
\renewcommand{\today}{~}
\hypersetup{pdfpagemode=Fullscreen,
  colorlinks=true,
  linkfileprefix={}}
\newcommand{\floor}[1]{\lfloor #1\rfloor}
\begin{document}
\maketitle

\begin{enumerate}
\item For the probability distribution
    \begin{table}[h] \centering
      \begin{tabular}{c|c|c|c|c}
        $x$ & 0 & 1 & 2 & 3 \\ \hline
        $p(x)$& 0.3 & 0.4 & 0.2&$k^2$
      \end{tabular}
    \end{table}
    \begin{enumerate}
    \item [(a)] Find: $k$
        \begin{itemize}
        \item We know that the total probability must equal 1, so therefore $0.3 + 0.4 + 0.2 + k^2 = 1$.
        \item Then $k = \sqrt{1 - 0.2 - 0.4 - 0.3} \approx 0.3162$
        \end{itemize}
    \item [(b)] Find $P(0< X \le 2)$:
        \begin{itemize}
        \item{itemize} To do this, we can simply add the discrete probabilities $p(0) + p(1) + p(2)$.
        \item{itemize} Then $P(0< X \le 2) = 0.3 + 0.4 + 0.2 = 0.9$
        \end{itemize}
    \item [(c)] Find $F(x)$, the cumulative distribution function:
        \begin{equation*}
        F(x) = \begin{cases}
            0.3, & x < 1 \\
            0.7, & 1 \leq x < 2 \\
            0.9, & 2 \leq x < 3 \\
            1,   & 3 \leq x < 4 \\
        \end{cases}
        \end{equation*}
    \item [(d)] Graph $F(x)$: \\
        \begin{tikzpicture}
            \begin{scope}
                \begin{axis}[xlabel={x},ylabel=F(x)]
                    \addplot[domain=0:1]{0.3};
                    \addplot[domain=1:2]{0.7};
                    \addplot[domain=2:3]{0.9};
                    \addplot[domain=3:4]{1};
                    \addplot[holdot] coordinates{(1,0.3)(2,0.7)(3,0.9)(4,1)};
                    \addplot[soldot] coordinates{(0,0.3)(1,0.7)(2,0.9)(3,1)};
                \end{axis}
            \end{scope}
        \end{tikzpicture}
        \end{enumerate}
    \item [(e)] Find $E(X)$:
        \begin{itemize}
        \item The expected value is simply the weighted average of all values.
        \item This can be found with $E(X) = (0)(0.3) + (1)(0.4) + (2)(0.2) + (3)(0.1) = 1.1$.
        \end{itemize}
    \item [(f)] Find $Var(X)$;
        \begin{itemize}
        \item The variance can be expressed as $Var(X) = E(X^2) - E(X)$.
        \item Therefore the variance is $Var(X) = E(X^2) - E(X)= (0.3)(0)^2 + (0.4)(1)^2 + (0.2)(2)^2 + (0.1)(3)^2 - 1.1= 1$.
        \end{itemize}

\item Let X be a discrete random variable with the following a cumulative distribution function.
    \begin{itemize}
    \item [(a)] $P(X = 5)$
        \begin{itemize}
        \item The answer is contained in the given function: $\frac{3}{4} - \frac{1}{2} = \frac{1}{4}$
        \end{itemize}
    \item [(b)] $P(1.3 < X < 6)$:
        \begin{itemize}
        \item This is a discrete distribution, so then $P(1.3 < X < 3) = 0$ and $P(5 \leq X < 6) = P(5 \leq X < 7)$.
        \item Then $P(1.3 < x < 6) = P(1.3 < X < 3) + P(3 \leq X < 5) + P(5 \leq X < 7) = 0 + \frac{1}{4} + \frac{1}{4} = \frac{1}{2}$
        \end{itemize}
    \item [(c)] $P(X \le 5|X \ge 2)$:
        \begin{itemize}
        \item Again, since this is discrete, $P(X \geq 2) = P(X \geq 3)$.
        \item So $P(X \le 5|X \ge 2)$ = $\frac{P(X = 5) + P(X = 3)}{P(X = 3) + P(X = 5) + P(X = 7)} = \frac{1/2}{3/4} = \frac{3}{8}$.
        \end{itemize}
    \item [(d)] $E(X) = (0)(0) + (\frac{1}{4})(1) + (\frac{1}{4})(3) + (\frac{1}{4})(5) + (\frac{1}{4})(7) = 4$
    \item [(e)] $Var(x) = E(X^2) - E(X) = (0)(0) + (\frac{1}{4})(1)^2 + (\frac{1}{4})(3)^2 + (\frac{1}{4})(5)^2 + (\frac{1}{4})(7)^2  - 4 = 21 - 4 = 17$
    \end{itemize}

\item Let $X$ be the number of times a basketball player scores in free throws. Suppose that the probability that he scores at least once in six free throws is equal to 0.999936.
    \begin{enumerate}
    \item [(a)] Find the probability mass function of  $X$.
        \begin{itemize}
        \item The probability of scoring at least one in six throws is $P(x \geq 1) = 1 - P(0) = 0.999936$.
        \item Then $P(0) = 0.000064 = (1 - p)^{6}$.
        \item Then $p = \frac{4}{5}$.
        \item So the probability mass function is $p(x) = \binom{n}{x} \frac{4}{5}^x \frac{1}{5}^{n-x}, x \in \mathbb{N}$
        \end{itemize}
    \item [(b)] Find $P(X \ge 3)$. [You can use R to find the answer]
        \begin{itemize}
        \item Using R, $pbinom(2, size=6, prob=0.2) = 0.90112$
        \end{itemize}
    \item [(c)] Find $E(X(X-1))$.
        \begin{itemize}
        \item Note that $E(X(X - 1)) = E(X^2 - X) = E(X^2) - E(X)$.
        \item Then $E(X^2) - E(X) = np(1 - p) + n^2p^2 - np$ using definitions from the lectures.
        \item Then $E(X^2) - E(X) = np(1 - p + np - 1) = np^2(n - 1)$
        \item Then $E(X^2) - E(X) = n(\frac{4}{5})^2(n - 1)$
        \item Then $E(X(X - 1)) = n\frac{16}{25}(n - 1)$
        \end{itemize}
    \end{enumerate}

\item Suppose $X\sim Poisson (\lambda)$.
    \begin{itemize}
    \item [(a)] Show that $p(k+1)=\frac{\lambda}{k+1}p(k)$, where $p(k)=P(X=k)$.
        \begin{itemize}
        \item This can be proven like any recursive algorithim. For $k \in \mathbb{N}$, define $D(k)$ to be that $p(k)=P(X=k)$.
        \item \underline{Base case}: $D(0)$.
            \begin{itemize}
            \item Note that $0, 1 \in \mathbb{N}$.
            \item Then $p(0) = \frac{\lambda^0 e^{-\lambda}}{0!} = e^{-\lambda}$ by definition of a Poisson distribution.
            \item Also $p(1) = \frac{\lambda^1 e^{-\lambda}}{1!} = \frac{\lambda}{0 + 1} e^{-\lambda}$ by the same definition.
            \item Then $p(1) = p(0 + 1) = \frac{\lambda}{0+1}p(0)$.
            \item Then for $k = 0, D(0)$.
            \end{itemize}
        \item \underline{Inductive step}: Assume $k \in \mathbb{N}, D(k)$
            \begin{itemize}
            \item Then $p(k) = \frac{\lambda^k e^{-\lambda}}{k!}$ by IH and definition of a Poisson distribution.
            \item Then $p(k+1) = \frac{\lambda^{k+1} e^{-\lambda}}{(k+1)!}$.
            \item Then $p(k+1) = \frac{\lambda \lambda^k e^{-\lambda}}{(k+1)(k)!}$.
            \item Then $p(k+1) = \frac{\lambda}{k+1} \frac{\lambda^k e^{-\lambda}}{k!}$.
            \item Then $p(k+1) = \frac{\lambda}{k+1} p(k)$.
            \item Then $D(k+1)$.
            \end{itemize}
        \item Then $p(k+1)=\frac{\lambda}{k+1}p(k)$.
        \end{itemize}
    \item [(b)] If $\lambda=2$, compute $p(0)$.
        \begin{itemize}
        \item In the base case of the above proof, we found $p(0) = e^{-\lambda}$.
        \item So for $\lambda=2$, $p(0) = e^{-2} \approx 0.1353$
        \end{itemize}
    \item [(c)] Use the recursive relation in (a) and and $p(0)$ in (b), to find $p(1),p(2),p(3),$ and $p(4)$.
        \begin{itemize}
        \item $p(1) = \frac{2}{1+1}p(0) = e^{-2} \approx 0.1353$
        \item $p(2) = \frac{2}{3}p(1) = \frac{2}{3} e^{-2} \approx 0.0902$
        \item $p(3) = \frac{2}{4}p(2) = \frac{2}{4} \frac{2}{3} e^{-2} \approx 0.0451$
        \item $p(4) = \frac{2}{5}p(2) = \frac{2}{5} \frac{2}{4} \frac{2}{3} e^{-2} \approx 0.0180$
        \end{itemize}
    \end{itemize}
\item Questions:
    \begin{itemize}
    \item [(a)] A random variable $X$ has a binomial distribution, and a random variable $Y$ has a Poisson distribution. If $E(X)=E(Y)$, determine which random variable has the larger variance. Explain.
        \begin{itemize}
        \item Although it was not stated, for the purpose of the question I am assuming that the probability $p$ is non-zero.
        \item If $E(X) = E(Y)$, then $np = \lambda$. Also, $V(Y) = \lambda$.
        \item Also $np(1 - p) < np$ since it simplifies to $-p < 0$, and $p \in \mathbb{R}, 0 < p \leq 1$.
        \item Then $np(1 - p) < \lambda$.
        \item Then $V(X) < V(Y)$.
        \end{itemize}
    \item [(b)] If $X\sim Bin(n,0.5)$, show that $p(k+1)=\frac{n-k}{k+1}p(k),\ \ k=0,1,\ldots, n-1$, where $p(k)=P(X=k)$.
        \begin{itemize}
        \item We know that $p(k) = \binom{n}{k} p^k (1 - p)^{n-k}$.
        \item Then $p(k) = \frac{n!}{k!(n-k)!} p^k (1 - p)^{n-k}$.
        \item Then $p(k) = \frac{n!}{k!(n-k)!} p^k (1 - p)^{n-k}$.
        \item Then $p(k+1) = \frac{n!}{k!(n-k-1)!} p^{k+1} (1 - p)^{n-k-1}$.
        \item Then $p(k+1) = \frac{n-k}{k+1} \frac{n!}{k!(n-k)!} \frac{p}{1-p} p(1-p)^{n-k}$
        \item Then $p(k+1) = \frac{n-k}{k+1} p(k)$
        \end{itemize}
    \item [(c)] The number of telephone calls arriving at an exchange during any one hour period is a Poisson random variable with $\lambda=10$. Find the probability that during a fifteen-minute period there will be 4 calls.
        \begin{itemize}
        \item This is just plugging into the equations we know. If there's an average of 10 calls per hour, by definition there must be an average of 2.5 calls every 15 minutes.
        \item Then we simply find $p(4)$ for $\lambda = 2.5$, which is $p(4) = \frac{2.5^4 e^{-4}}{4!} \approx 0.0298 $
        \end{itemize}
    \end{itemize}
\item Let $X \sim Geometric(p)$.
    \begin{enumerate}
    \item [(a)] Show that $P(X>k)=(1-p)^k$ for any integer $k$.
        \begin{itemize}
        \item We know that the probability distribution is $p(x) = p(1 - p)^{x-1}$.
        \item Therefore $p(x + 1) = p(1 - p)^x$, and the probability $P(X > k) = \sum_{x=0}^k = \frac{r - r^{k+1}}{1-r}$
        \end{itemize}
    \item [(b)] Show that  $P(X> j+k|X > j)=P(X > k)$ for any integer $j,k\ge 0.$
        \begin{itemize}
        \item We know that $P(X > j) = (1 - p)^j$ by part a, and the $P(X > j + k) = (1 - p)^{j + k}$
        \item Then $P(X > j + k | X > j) = \frac{P(X > j + k)}{P(X > j)} = \frac{(1 - p)^{j + k}}{(1 - p)^{j}} = (1 - p)^k$
        \item Then $P(X > j + k | X > j) = P(X > k)$
        \end{itemize}
    \end{enumerate}
\item Let $X$ be a Poisson random variable such that $P(X=2)=\frac{2}{3}P(X=1)$.
    \begin{enumerate}
    \item [(a)] Find $E(X(X-1))$.
        \begin{itemize}
        \item First off, we were given that $P(X=2)=\frac{2}{3}P(X=1)$. Therefore $\frac{\lambda^2 e^{-\lambda}}{2!}=\frac{2}{3}\frac{\lambda^1 e^{-\lambda}}{1!}$.
        \item We can solve this and find that either $\lambda = 0$ or $\lambda = \frac{4}{3}$. I'll presume the latter solution is the one we're interested in.
        \item Then $E(X(X-1)) = E(X^2 - X) = \lambda^2 - \lambda = \frac{16}{9} - \frac{4}{3}$.
        \item Then $E(X(X-1)) = \frac{4}{9} \approx 0.4444$.
        \end{itemize}
    \item [(b)] Find $P(X \ge 1)$.
        \begin{itemize}
        \item $P(X \ge 1) = 1 - P(X = 0)$ since $X \in \mathbb{N}$.
        \item Then $P(X \ge 1) = 1 - \frac{(4/3)^0 e^{-4/3}}{0!}$
        \item Then $P(X \ge 1) = 1 - e^{-\frac{4}{3}} \approx 0.7364$
        \end{itemize}
    \item [(c)] Find $P(X \le 10)$. [Use R to find the answer].
        \begin{itemize}
        \item Evaluated using R, $ppois(10, 4/3) = 1.000$
        \end{itemize}
    \end{enumerate}

\item Use only the properties the Binomial, Geometric and Poisson distributions to find the exact value of the following sums:
    \begin{enumerate}
    \item [(a)] $\sum_{x=0}^{500} \frac{x-2}{x!(500-x)!}~(0.4)^x~(0.6)^{500-x}$.
        \begin{itemize}
        \item Note that $E(X)$ is defined as $E(X) = \sum_{x} x p(x)$.
        \item Then $\frac{1}{500!} \sum_{x=0}^{500} \frac{(x-2)500!}{x!(500-x)!}~(0.4)^x~(0.6)^{500-x}$
        \item Then the summation is equivalent to $\frac{1}{500!} E(X - 2) = \frac{(500 \times 0.4) - 2}{500!}$
        \item Then $\sum_{x=0}^{500} \frac{x-2}{x!(500-x)!}~(0.4)^x~(0.6)^{500-x} = \frac{198}{500!} = 1.623 \times 10^{-1132}$
        \end{itemize}
    \item [(b)] $\sum_{x=0}^{\infty}\frac{x^2 2^x}{x!}$.
        \begin{itemize}
        \item Note that $E(X^2) = \sum_{x} x^2 p(x) $.
        \item Then for a Poisson distribution $E(X^2) = \sum_{x=0}^{\infty} x^2 \frac{\lambda^x e^{-\lambda}}{x!}$
        \item Then $E(X^2) = e^{-\lambda} \sum_{x=0}^{\infty} \frac{\lambda^x x^2}{x!}$
        \item Then $\sum_{x=0}^{\infty} \frac{\lambda^x x^2}{x!} = E(X^2)e^\lambda = (\lambda^2 + \lambda)e^\lambda$
        \item Then $\sum_{x=0}^{\infty} \frac{2^x x^2}{x!} = E(X^2)e^2 = (2^2 + 2)e^2 = 6 e^2$
        \end{itemize}
    \item [(c)] $\sum_{x=0}^{\infty}\frac{2^x}{x!}$.
        \begin{itemize}
        \item Recall that the sum of any probability distribution is 1. That is, $\sum_{x} p(x) = 1$.
        \item For a Poisson distribution, that is $\sum_{x=0}^{\infty} \frac{\lambda^x e^{-\lambda}}{x!} = 1$.
        \item Then $e^{-\lambda} \sum_{x=0}^{\infty} \frac{\lambda^x}{x!} = 1$.
        \item Then $\sum_{x=0}^{\infty} \frac{\lambda^x}{x!} = e^{\lambda}$.
        \item Then $\sum_{x=0}^{\infty} \frac{2^x}{x!} = e^2$.
        \end{itemize}
    \item [(d)] $\sum_{x=0}^{\infty}\frac{(x^2-x+1)2^x}{x!}$.
        \begin{itemize}
        \item For any distribution, $E(x^2 - x + 1) = \sum_{x} (x^2 - x + 1)p(x)$.
        \item Then for a Poisson distribution:
        \begin{equation*}
        \begin{aligned}
            E(X^2 - X + 1) =& \sum_{x=0}^{\infty} (x^2 - x + 1) \frac{\lambda^x e^{-\lambda}}{x!} \\
            E(X^2) - E(X) + 1 =& e^{-\lambda} \sum_{x=0}^{\infty} \frac{(x^2 - x + 1) \lambda^x}{x!} \\
            (E(X^2) - E(X) + 1)e^{\lambda} =&  \sum_{x=0}^{\infty} \frac{(x^2 - x + 1) \lambda^x}{x!} \\
            (\lambda^2 + \lambda - \lambda + 1)e^{\lambda} =& \sum_{x=0}^{\infty} \frac{(x^2 - x + 1) \lambda^x}{x!} \\
            (2^2 + 2 - 2 + 1)e^2 =& \sum_{x=0}^{\infty} \frac{(x^2 - x + 1) 2^x}{x!}
        \end{aligned}
        \end{equation*}
        \item Then $\sum_{x=0}^{\infty}\frac{(x^2-x+1)2^x}{x!} = 5e^2 \approx 36.95$
        \end{itemize}
    \item [(e)] $\sum_{x=1}^{\infty}\frac{x^2}{2^x}$.
    \end{enumerate}
\end{enumerate}

\end{document}
